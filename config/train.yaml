operation:
  name: "train"


dataset:
  train_images_path: "dummy_data/dataset/train/images"
  val_images_path: "dummy_data/dataset/val/images"
  train_captions_path: "dummy_data/dataset/train/captions"
  val_captions_path: "dummy_data/dataset/val/captions"
  test_captions_path: "dummy_data/dataset/test/captions"
  test_images_path: "dummy_data/dataset/test/images"
  train_bs: 4
  val_bs: 1
  test_bs: 1
  augmentation: [Resize, RandomHorizontalFlip, Normalize]
  image_size: [512, 512]


model_arch:
  # Structured component specifications
  vae:
    module: "model_arch.flux_vae.AutoEncoder"
    params:
      in_channels: 3
      z_channels: 16
      scale_factor: 0.3611
      shift_factor: 0.1159
  text_encoder:
    module: "model_arch.vanilla_embedder.VanillaEmbedder"
    params:
      vocab_size: 1001
      embedding_dim: 768
      return_datum_lens: true
  clip_encoder:
    module: "model_arch.vanilla_embedder.VanillaEmbedder"
    params:
      vocab_size: 1001
      embedding_dim: 768
      return_datum_lens: false
  patchifier:
    module: "model_arch.patchifier.Patchifier"
    params:
      patch_size: [ 1, 2, 2 ] # [frames, height, width] - DiT typical
      vae_latent_channels: 16 # VAE latent channels
      # must agree with vae
      vae_compression_factors: [ 1, 8, 8 ] # VAE compression factors [frames, height, width]
  denoiser:
    module: "model_arch.flux_denoiser.FluxDenoiser"
    params:
      d_model: 1024
      d_head: 64
      # n_ds_blocks: 19
      # n_ss_blocks: 38
      n_ds_blocks: 8
      n_ss_blocks: 16
      d_txt: 768
      d_vec: 768
      # must match vae_latent_channels * prod(vae_compression_factors) in patchifier
      d_img: 64
      # must have sum equal to d_head;
      # must have number of elements equal to patch_size in patchifier
      rope_axis_dim: [ 8, 28, 28 ] # tyx coordinates
      guidance_embed: false
    fsdp:
      meta_device_init: true
      shard_size: 1
      param_dtype: "bf16"
      reduce_dtype: "fp32"
      ac_freq: 0
      blocks_attr: [ "double_blocks", "single_blocks" ]
      reshard_after_forward_policy: "default"
      blocks_per_shard_group: 12 # -1


  time_sampler:
    module: "sampler.noiser.TimeSampler"
    params:
      use_logit_normal: false
      mu: 0.0 # Mean of the logit normal distribution
      sigma: 1.0 # Standard deviation of the logit normal distribution

  time_warper:
    module: "sampler.noiser.TimeWarper"
    params:
      base_len: 256 # Base sequence length
      base_shift: 0.5 # Base shift parameter for time warping
      max_len: 4096 # Maximum sequence length
      max_shift: 1.15 # Maximum shift parameter for time warping
  
  time_weighter:
    module: "sampler.noiser.TimeWeighter"
    params:
      use_logit_normal: true
      mu: 0.0 # Mean of the logit normal distribution
      sigma: 1.0 # Standard deviation of the logit normal distribution
  flow_noiser:
    module: "sampler.noiser.FlowNoiser"
    params:
      compute_dtype: "fp32" # Internal computation dtype: "fp32", "fp16", "bf16"
