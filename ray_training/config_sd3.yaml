# --------- Encoding (Ray Data) ----------
# csv: "data/dataset.csv"
csv: "eros_data/captions_dataset.csv"
resolution: 256
batch_size: 256
parallelism: 8
min_aesthetic: null

enc_vae_model: "stabilityai/stable-diffusion-3-medium-diffusers"
enc_clip_l_model: "openai/clip-vit-large-patch14"
enc_clip_g_model: "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k"
enc_t5_model: "google/t5-v1_1-xxl"
enc_dtype: "bfloat16"
enc_num_actors: 2
keep_intermediate_tensors: false

# --------- Training ----------
experiment_name: "sd3_dit_lightning"
storage_path: "./ray_results"
num_training_workers: 8
batch_size_per_worker: 4
prefetch_batches: 2
num_epochs: 1000
max_steps: -1
train_split: 0.75
seed: 420

# --------- Validation Prompts ----------
validation_prompts:
  - "the person in the image appears to be an Indian man with dark hair styled upwards. He has a mustache and is wearing a light-colored shirt. His facial expression suggests he might be speaking or reacting to something as his mouth is slightly open and his eyes are focused."
validation_inference_steps: 500  # Number of denoising steps for validation
validation_frequency: 10  # Generate validation images every N epochs (0 = disable)
validation_output_dir: "/data0/teja_codes/ImmersoAiResearch/FlowModelTraining/miniDiffusion/ray_training/logs/valid_imgs"  # Directory to save validation images
validation_debug: false  # Enable debug logging for validation generation

# --------- Checkpoint Configuration ----------
checkpoint_frequency: 10  # Save checkpoint every N epochs (0 = save every epoch)

# --------- Precision Configuration ----------
dtype: "bfloat16"  # Options: "float16", "bfloat16", "float32"

lr: 1.0e-4
weight_decay: 1.0e-2
warmup_steps: 1000
accumulate_steps: 1
grad_clip_norm: 1.0
precision: "bf16-mixed"   # or "16-mixed"
fsdp: false               # true -> FSDP, false -> DDP
max_failures: 3
